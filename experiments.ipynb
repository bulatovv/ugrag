{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0495fcaa-b589-40ec-99e6-34b685f94e4b",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d4023fca-ed23-4dde-9fa1-c7ac62f7abb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import warnings\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import get_dataset_config_names\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "logging.debug(\"info\")\n",
    "\n",
    "logging.getLogger(\"urllib3\").setLevel(logging.WARNING),\n",
    "logging.getLogger('opensearch').setLevel(logging.WARNING),\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "75bf03b6-25e3-4c25-9ab2-66188f7630eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['covidqa',\n",
       " 'cuad',\n",
       " 'delucionqa',\n",
       " 'emanual',\n",
       " 'expertqa',\n",
       " 'finqa',\n",
       " 'hagrid',\n",
       " 'hotpotqa',\n",
       " 'msmarco',\n",
       " 'pubmedqa',\n",
       " 'tatqa',\n",
       " 'techqa']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsets = get_dataset_config_names('rungalileo/ragbench')\n",
    "\n",
    "subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "3841977c-a067-4662-8379-c4132bff4a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Dataset named 'covidqa' downloaded with shape: '(1765, 28)'\n",
      "INFO:__main__:Dataset named 'cuad' downloaded with shape: '(2550, 28)'\n",
      "INFO:__main__:Dataset named 'delucionqa' downloaded with shape: '(913, 28)'\n",
      "INFO:__main__:Dataset named 'emanual' downloaded with shape: '(659, 28)'\n",
      "INFO:__main__:Dataset named 'expertqa' downloaded with shape: '(2027, 28)'\n",
      "INFO:__main__:Dataset named 'finqa' downloaded with shape: '(8281, 28)'\n",
      "INFO:__main__:Dataset named 'hagrid' downloaded with shape: '(4532, 28)'\n",
      "INFO:__main__:Dataset named 'hotpotqa' downloaded with shape: '(2697, 28)'\n",
      "INFO:__main__:Dataset named 'msmarco' downloaded with shape: '(2690, 28)'\n",
      "INFO:__main__:Dataset named 'pubmedqa' downloaded with shape: '(12250, 28)'\n",
      "INFO:__main__:Dataset named 'tatqa' downloaded with shape: '(16552, 28)'\n",
      "INFO:__main__:Dataset named 'techqa' downloaded with shape: '(905, 28)'\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "\n",
    "for subset in subsets:\n",
    "    df = pd.read_parquet(f'hf://datasets/rungalileo/ragbench/{subset}')\n",
    "    \n",
    "    df['question_id'] = df.index\n",
    "    df['n_relevant'] = df['all_relevant_sentence_keys'].apply(lambda x: len(x) if type(x) is list else 0)\n",
    "    \n",
    "    df.sort_values(by=['id', 'n_relevant'], ascending=[False, False], inplace=True)\n",
    "    df.drop_duplicates(subset=['id'], keep='first', inplace=True)\n",
    "\n",
    "    logger.info(\"Dataset named '%s' downloaded with shape: '%s'\", subset, df.shape)\n",
    "    data[subset] = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d4532a-916f-4ab0-94a0-2089344116dd",
   "metadata": {},
   "source": [
    "## Embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a906b67-c527-4410-8688-ca3a05cd1c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class EmbedderSettings(BaseModel):\n",
    "    batch_size: int = 16\n",
    "    model_name: str\n",
    "    type_model: str\n",
    "    dimension: int\n",
    "    prefix_query: str\n",
    "    prefix_document: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0bb7b9d-2cfe-4db9-af02-c5fc06da3fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "e5_embedder_settings = EmbedderSettings(batch_size=16, \n",
    "                                     model_name='intfloat/multilingual-e5-base', \n",
    "                                     type_model=\"\", \n",
    "                                     dimension=768, \n",
    "                                     prefix_query=\"query: {}\",\n",
    "                                     prefix_document=\"passage: {}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6fc8336-0112-4452-9196-f40165155bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import abc\n",
    "from typing import List\n",
    "\n",
    "import more_itertools\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModel, AutoTokenizer, XLMRobertaModel, XLMRobertaTokenizer\n",
    "\n",
    "\n",
    "class IEmbedder(abc.ABC):\n",
    "    def __init__(self):\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device(\"cuda\")\n",
    "        else:\n",
    "            self.device = torch.device(\"cpu\")\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def encode(self, sentences: List[str], doc_type: str) -> np.ndarray:\n",
    "        \"\"\"Calculate sentences embedding(s)\"\"\"\n",
    "\n",
    "\n",
    "class Embedder(IEmbedder):\n",
    "    def __init__(self, settings: EmbedderSettings):\n",
    "        super().__init__()\n",
    "        self._settings = settings\n",
    "        self.batch_size = self._settings.batch_size\n",
    "        self.model_type = self._settings.type_model\n",
    "        self.prefix_query = self._settings.prefix_query\n",
    "        self.prefix_document = self._settings.prefix_document\n",
    "\n",
    "        if self.model_type == 'e5':\n",
    "            self.model = XLMRobertaModel.from_pretrained(self._settings.model_name).to(self.device)\n",
    "            self.tokenizer = XLMRobertaTokenizer.from_pretrained(self._settings.model_name)\n",
    "        else:\n",
    "            self.model = AutoModel.from_pretrained(self._settings.model_name).to(self.device)\n",
    "            self.tokenizer = AutoTokenizer.from_pretrained(self._settings.model_name)\n",
    "\n",
    "    @staticmethod\n",
    "    def average_pool(last_hidden_states: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "        return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "    def encode(self, sentences: List[str], doc_type: str) -> np.ndarray:\n",
    "        sentences = self.preprocess_sentences(sentences, doc_type)\n",
    "        embeddings = torch.tensor([]).to(self.device)\n",
    "\n",
    "        for batch in more_itertools.chunked(sentences, self.batch_size):\n",
    "            tokenized_batch = self.tokenizer(batch, max_length=512, padding=True,\n",
    "                                             truncation=True, return_tensors='pt').to(self.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**tokenized_batch).last_hidden_state\n",
    "                embed = self.average_pool(outputs, tokenized_batch['attention_mask'])\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            for tensor in embed:\n",
    "                embeddings = torch.cat((embeddings, tensor.unsqueeze(0)), 0)\n",
    "\n",
    "        return np.array([torch.Tensor.cpu(emb) for emb in F.normalize(embeddings, dim=-1)])\n",
    "\n",
    "    def preprocess_sentences(self, sentences: List[str], doc_type: str) -> List[str]:\n",
    "        if doc_type == 'query':\n",
    "            return [self.prefix_query.format(sentence) for sentence in sentences]\n",
    "        elif doc_type == 'document':\n",
    "            return [self.prefix_document.format(sentence) for sentence in sentences]\n",
    "        return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eed25cd7-a26c-409b-947a-f2ddbd650e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = Embedder(e5_embedder_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9158f333-b127-48b1-98cc-d0a3b7b41cc1",
   "metadata": {},
   "source": [
    "## Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "753e9f9e-096c-44ea-b243-43b743d9dbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "\n",
    "SQLALCHEMY_DATABASE_URL = \"postgresql://user:password@localhost:5434/ugragdb\"\n",
    "\n",
    "engine = create_engine(SQLALCHEMY_DATABASE_URL)\n",
    "SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n",
    "Base = declarative_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e654ced5-c309-48b6-a2fb-c81470e333ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgvector.sqlalchemy import Vector\n",
    "from sqlalchemy import Column, Date, ForeignKey, Integer, String, Text\n",
    "\n",
    "\n",
    "dimension = 768\n",
    "table_class_cache = {}\n",
    "\n",
    "\n",
    "def create_document_table_class(table_name: str):\n",
    "    if table_name in table_class_cache:\n",
    "        return table_class_cache[table_name]\n",
    "        \n",
    "    class DBTable(Base):\n",
    "        __tablename__ = table_name\n",
    "\n",
    "        id = Column(String, primary_key=True, index=True)\n",
    "        doc_id = Column(String, nullable=False)\n",
    "        question_id = Column(String, nullable=False)\n",
    "        text = Column(Text, nullable=False)\n",
    "        vector = Column(Vector(dimension))\n",
    "\n",
    "    table_class_cache[table_name] = DBTable\n",
    "\n",
    "    return DBTable\n",
    "\n",
    "\n",
    "for table_name in subsets:\n",
    "    DocumentTableClass = create_document_table_class(table_name)\n",
    "Base.metadata.create_all(bind=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "a9cb7632-99cb-4c6d-971f-ffde3f1fcde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Table 'covidqa' loading...\n",
      "INFO:__main__:Table 'cuad' loading...\n",
      "INFO:__main__:Table 'delucionqa' loading...\n",
      "INFO:__main__:Table 'emanual' loading...\n",
      "INFO:__main__:Table 'expertqa' loading...\n",
      "INFO:__main__:Table 'finqa' loading...\n",
      "INFO:__main__:Table 'hagrid' loading...\n",
      "INFO:__main__:Table 'hotpotqa' loading...\n",
      "INFO:__main__:Table 'msmarco' loading...\n",
      "INFO:__main__:Table 'pubmedqa' loading...\n",
      "INFO:__main__:Table 'tatqa' loading...\n",
      "INFO:__main__:Table 'techqa' loading...\n"
     ]
    }
   ],
   "source": [
    "db = SessionLocal()\n",
    "\n",
    "for subset in subsets:\n",
    "    DocumentTableClass = table_class_cache[subset]\n",
    "    logger.info(\"Table '%s' loading...\", DocumentTableClass.__table__)\n",
    "    table_df = data[subset]\n",
    "\n",
    "    for question_id, document_sentences in zip(table_df['question_id'].values, table_df['documents_sentences'].values), total=len(table_df):\n",
    "        for doc_group in document_sentences:\n",
    "            for doc in doc_group:\n",
    "                doc_id = doc[0]\n",
    "                doc_text = doc[1]\n",
    "                key_id = f\"{question_id}_{doc_id}\"\n",
    "    \n",
    "                embedding = embedder.encode([doc_text], doc_type=\"document\")[0]\n",
    "    \n",
    "                db_doc = DocumentTableClass(id=key_id, doc_id=doc_id,\n",
    "                                      question_id=str(question_id),\n",
    "                                      text=doc_text,\n",
    "                                      vector=embedding)\n",
    "                db.add(db_doc)\n",
    "        db.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971e01a8-e10a-4c59-ac3b-f3f20d4016b4",
   "metadata": {},
   "source": [
    "## ElasticSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e15284f1-b812-48ef-94f1-70cdd4bafb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Any, Dict, Iterator, List\n",
    "\n",
    "import more_itertools\n",
    "from opensearchpy import OpenSearch, OpenSearchException\n",
    "from opensearchpy.helpers import bulk\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def create_index(index_name: str, os_client: OpenSearch) -> None:\n",
    "    mapping: Dict = {\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"text\": {\"type\": \"text\"},\n",
    "                \"doc_id\": {\"type\": \"keyword\"},\n",
    "                \"question_id\": {\"type\": \"keyword\"}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if not os_client.indices.exists(index=index_name):\n",
    "        os_client.indices.create(index=index_name, body=mapping)\n",
    "        logger.info(f\"Successfully created index {index_name}\")\n",
    "\n",
    "\n",
    "def load(df: pd.DataFrame) -> Iterator[Any]:\n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            yield generate_document_source(row.to_dict())\n",
    "        except Exception:\n",
    "            raise\n",
    "\n",
    "def generate_document_source(row: Dict) -> Dict:\n",
    "    result = {\n",
    "        \"id\": row['key_id'],\n",
    "        \"text\": row['doc_text'],\n",
    "        \"doc_id\": row['doc_id'],\n",
    "        \"question_id\": row['question_id']\n",
    "    }\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def update_search(df: pd.DataFrame, os_client: OpenSearch, index_name: str, batch_size: int = 500) -> None:\n",
    "    create_index(index_name, os_client)\n",
    "    total_inserted_docs: int = 0\n",
    "    total_errors: int = 0\n",
    "\n",
    "    for chunk in more_itertools.ichunked(load(df), batch_size):\n",
    "        bucket_data = []\n",
    "        for document in chunk:\n",
    "            cur = {\n",
    "                \"_index\": index_name,\n",
    "                \"_source\": document,\n",
    "            }\n",
    "            if 'id' in document:\n",
    "                cur['_id'] = str(document['id'])\n",
    "            bucket_data.append(cur)\n",
    "        try:\n",
    "            inserted, errors = bulk(os_client, bucket_data, max_retries=4, raise_on_error=False)\n",
    "            errors_num = len(errors) if isinstance(errors, list) else errors  # type: ignore\n",
    "            logger.debug(f\"{inserted} docs successfully inserted by bulk with {errors_num} errors\")\n",
    "            total_inserted_docs += inserted\n",
    "            total_errors += errors_num\n",
    "            if isinstance(errors, list):  # type: ignore\n",
    "                for error in errors:  # type: ignore\n",
    "                    logger.error(f\"Doc was not inserted with error: {error}\")\n",
    "        except OpenSearchException as e:\n",
    "            logger.exception(f\"Error while pushing data to elasticsearch: {e}\")\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "35688673-c647-4d9f-a585-87466b4fdf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "os_client = OpenSearch(([{\"host\": \"localhost\", \"port\": 9200}]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7e890c0e-425d-452d-b39c-bdefb89d5816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fulltext_df(subset: str) ->pd.DataFrame:\n",
    "    doc_ids, doc_texts, key_ids, question_ids = [], [], [], []\n",
    "\n",
    "    for question_id, document_sentences in zip(data[subset]['question_id'].values, \n",
    "                                               data[subset]['documents_sentences'].values):\n",
    "        for doc_group in document_sentences:\n",
    "            for doc in doc_group:\n",
    "                doc_ids.append(doc[0])\n",
    "                doc_texts.append(doc[1])\n",
    "                key_ids.append(f\"{question_id}_{doc[0]}\")\n",
    "                question_ids.append(str(question_id))\n",
    "\n",
    "    logger.info(\"for subset '%s' got data to load to index with size: '%s'\", subset, len(key_ids))\n",
    "    return pd.DataFrame({'key_id': key_ids, 'question_id': question_ids, 'doc_id': doc_ids, 'doc_text': doc_texts})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "131cb133-7a13-430a-98bd-cb3087c12fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1765/1765 [00:00<00:00, 84152.12it/s]\n",
      "INFO:__main__:for subset 'covidqa' got data to load to index with size: '32392'\n",
      "INFO:__main__:Successfully created index covidqa\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 913/913 [00:00<00:00, 69366.90it/s]\n",
      "INFO:__main__:for subset 'delucionqa' got data to load to index with size: '36121'\n",
      "INFO:__main__:Successfully created index delucionqa\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 659/659 [00:00<00:00, 107487.71it/s]\n",
      "INFO:__main__:for subset 'emanual' got data to load to index with size: '18812'\n",
      "INFO:__main__:Successfully created index emanual\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2027/2027 [00:00<00:00, 33856.69it/s]\n",
      "INFO:__main__:for subset 'expertqa' got data to load to index with size: '154396'\n",
      "INFO:__main__:Successfully created index expertqa\n"
     ]
    }
   ],
   "source": [
    "for subset in subsets:\n",
    "    fulltext_df = get_fulltext_df(subset)\n",
    "    update_search(fulltext_df, os_client, subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a8c167-3a8f-496f-ae53-ccb444301722",
   "metadata": {},
   "source": [
    "## Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c5fcad35-5e1b-44c1-9d9c-6c63e20ff54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_semantic_search(subset: str, query: str, question_id: str, top_k: int = 40, similarity_threshold: float = 0.8) -> list:\n",
    "    query_vector = embedder.encode([query], doc_type=\"query\")[0].tolist()\n",
    "    DocumentTableClass = table_class_cache[subset]\n",
    "    \n",
    "    results = (\n",
    "        db.query(\n",
    "            DocumentTableClass,\n",
    "            DocumentTableClass.vector.cosine_distance(query_vector).label(\"distance\"),\n",
    "        )\n",
    "        .filter(\n",
    "            DocumentTableClass.vector.cosine_distance(query_vector) < similarity_threshold,\n",
    "            DocumentTableClass.question_id == str(question_id)\n",
    "        )\n",
    "        .order_by(\"distance\")\n",
    "        .limit(top_k)\n",
    "        .all()\n",
    "    )\n",
    "    return [{\"text\": result.DocumentTableClass.text, \n",
    "             \"doc_id\": result.DocumentTableClass.doc_id,\n",
    "             \"score\": result[1]} for result in results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1daa60bd-71ad-4671-b759-38aa8c15d560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_fulltext_search(subset: str, query: str, question_id: str, top_k: int = 40) -> list:\n",
    "    query: Dict = {\"query\": {\n",
    "        \"bool\": {\n",
    "          \"must\": [\n",
    "            {\n",
    "              \"match\": {\n",
    "                \"text\": query\n",
    "              }\n",
    "            },\n",
    "            {\n",
    "              \"term\": {\n",
    "                \"question_id\": {\n",
    "                  \"value\": str(question_id)\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      }, \"size\": top_k}\n",
    "    response: dict = os_client.search(index=subset, body=query)\n",
    "\n",
    "    return [{\"text\": hit[\"_source\"]['text'], \n",
    "             \"doc_id\": hit[\"_source\"]['doc_id'],\n",
    "             \"score\": hit[\"_score\"]} for hit in response['hits']['hits']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "87847075-6cd1-47b8-add8-f721e8108139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_for_subset(subset: str) -> dict:\n",
    "    results = {'semantic_search_results': {}, 'fulltext_search_results': {}}\n",
    "\n",
    "    for question_id, query in tqdm(zip(data[subset]['question_id'].values, data[subset]['question'].values), total=len(data[subset])):\n",
    "        results['semantic_search_results'][str(question_id)] = retrieve_semantic_search(subset, query, question_id)\n",
    "        results['fulltext_search_results'][str(question_id)] = retrieve_fulltext_search(subset, query, question_id)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656f15e5-a25d-4320-9722-2cee6d3a37c9",
   "metadata": {},
   "source": [
    "## Reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "979c52d4-da47-4f30-8b2e-7ade661500ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "\n",
    "model = CrossEncoder(\"cross-encoder/stsb-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7bcad5b7-61d4-410a-b522-30c2bc93ba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_serp(subset: str) -> dict:\n",
    "    combined_search_results_v1 = {}\n",
    "\n",
    "    retrieved = retrieve_for_subset('delucionqa')\n",
    "    \n",
    "    for question_id in data[subset]['question_id'].values:\n",
    "        values = retrieved['fulltext_search_results'][str(question_id)] + \\\n",
    "                 retrieved['semantic_search_results'][str(question_id)]\n",
    "    \n",
    "        unique_data = {entry['doc_id']: entry for entry in values}\n",
    "        docs = list(unique_data.values())\n",
    "    \n",
    "        query = data[subset].loc[data[subset]['question_id']==question_id]['question'].values[0]\n",
    "        corpus = [val['text'] for val in docs]\n",
    "        \n",
    "        sentence_combinations = [[query, sentence] for sentence in corpus]\n",
    "        scores = model.predict(sentence_combinations)\n",
    "        \n",
    "        for score, doc in zip(scores, docs):\n",
    "            doc['ml_score'] = score\n",
    "        \n",
    "        combined_search_results_v1[str(question_id)] = sorted(docs, key=lambda x: x['ml_score'], reverse=True)\n",
    "\n",
    "    return combined_search_results_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123a8e2c-4d95-4e6d-9bd4-286fd3296286",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f5b68183-f93b-4f9e-a9a3-318d175cde07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision_recall(true_relevance: list[str], retrieved_documents: list[str], at_k: int = 10) -> tuple[float, float, float]:\n",
    "    true_relevance = set(true_relevance)\n",
    "    retrieved_documents = set(retrieved_documents[:at_k])\n",
    "    \n",
    "    true_positives = true_relevance.intersection(retrieved_documents)\n",
    "    \n",
    "    precision = len(true_positives) / len(retrieved_documents)\n",
    "    recall = len(true_positives) / len(true_relevance)\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1_score\n",
    "\n",
    "\n",
    "def calculate_mrr(true_relevance: list[str], retrieved_documents: list[str], ks: list[int] = [1, 3, 5, 10]) -> dict[int, float]:\n",
    "    true_relevance = set(true_relevance)\n",
    "    mrr_scores = []\n",
    "    \n",
    "    for k in ks:\n",
    "        rank_found = 0\n",
    "        for i, doc_id in enumerate(retrieved_documents[:k], start=1):\n",
    "            if doc_id in true_relevance:\n",
    "                rank_found = i\n",
    "                break\n",
    "        mrr_scores.append(1 / rank_found if rank_found > 0 else 0)\n",
    "    \n",
    "    return mrr_scores\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def calculate_metrics(subset: str, df: pd.DataFrame, search_results: dict, model_name: str = 'deepvk/USER-base') -> pd.DataFrame:\n",
    "    metrics = {\n",
    "        k: {\n",
    "            'precisions': [],\n",
    "            'recalls': [],\n",
    "            'f1s': [],\n",
    "            'mrrs': []\n",
    "        } for k in [1, 3, 5, 10]\n",
    "    }\n",
    "    \n",
    "    for question_id, true_relevance in zip(df['question_id'].values, df['all_relevant_sentence_keys'].values):\n",
    "        if len(true_relevance) == 0:\n",
    "            continue\n",
    "            \n",
    "        relevances = [val['doc_id'] for val in search_results[str(question_id)]]\n",
    "        \n",
    "        mrr_values = calculate_mrr(true_relevance, relevances)\n",
    "\n",
    "        for idx, k in enumerate([1, 3, 5, 10]):\n",
    "            metrics[k]['mrrs'].append(mrr_values[idx])\n",
    "        \n",
    "            precision, recall, f1 = calculate_precision_recall(true_relevance, relevances, k)\n",
    "            metrics[k]['precisions'].append(precision)\n",
    "            metrics[k]['recalls'].append(recall)\n",
    "            metrics[k]['f1s'].append(f1)\n",
    "\n",
    "    rows = []\n",
    "    for k in [1, 3, 5, 10]:\n",
    "        if not metrics[k]['precisions']:  # Skip if no data\n",
    "            continue\n",
    "            \n",
    "        rows.append({\n",
    "            'model_name': model_name,\n",
    "            'subset': subset,\n",
    "            'k': k,\n",
    "            'precision': np.mean(metrics[k]['precisions']),\n",
    "            'recall': np.mean(metrics[k]['recalls']),\n",
    "            'f1': np.mean(metrics[k]['f1s']),\n",
    "            'mrr': np.mean(metrics[k]['mrrs'])\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(rows)[['model_name', 'subset', 'k', 'precision', 'recall', 'f1', 'mrr']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "29e40801-a7b3-45c8-8532-482403998809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>subset</th>\n",
       "      <th>k</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>mrr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>covidqa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>covidqa</td>\n",
       "      <td>3</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>covidqa</td>\n",
       "      <td>5</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>covidqa</td>\n",
       "      <td>10</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>cuad</td>\n",
       "      <td>1</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>cuad</td>\n",
       "      <td>3</td>\n",
       "      <td>0.467</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>cuad</td>\n",
       "      <td>5</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.587</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>cuad</td>\n",
       "      <td>10</td>\n",
       "      <td>0.367</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.481</td>\n",
       "      <td>0.641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>delucionqa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>delucionqa</td>\n",
       "      <td>3</td>\n",
       "      <td>0.594</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>delucionqa</td>\n",
       "      <td>5</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>delucionqa</td>\n",
       "      <td>10</td>\n",
       "      <td>0.483</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>emanual</td>\n",
       "      <td>1</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>emanual</td>\n",
       "      <td>3</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>emanual</td>\n",
       "      <td>5</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.458</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>emanual</td>\n",
       "      <td>10</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>expertqa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>expertqa</td>\n",
       "      <td>3</td>\n",
       "      <td>0.401</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>expertqa</td>\n",
       "      <td>5</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.415</td>\n",
       "      <td>0.501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>expertqa</td>\n",
       "      <td>10</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.621</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>finqa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>finqa</td>\n",
       "      <td>3</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>finqa</td>\n",
       "      <td>5</td>\n",
       "      <td>0.473</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>finqa</td>\n",
       "      <td>10</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>hagrid</td>\n",
       "      <td>1</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.313</td>\n",
       "      <td>0.387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>hagrid</td>\n",
       "      <td>3</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>hagrid</td>\n",
       "      <td>5</td>\n",
       "      <td>0.332</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>hagrid</td>\n",
       "      <td>10</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>hotpotqa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>hotpotqa</td>\n",
       "      <td>3</td>\n",
       "      <td>0.627</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>hotpotqa</td>\n",
       "      <td>5</td>\n",
       "      <td>0.583</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.659</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>hotpotqa</td>\n",
       "      <td>10</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.637</td>\n",
       "      <td>0.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>msmarco</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>msmarco</td>\n",
       "      <td>3</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.685</td>\n",
       "      <td>0.759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>msmarco</td>\n",
       "      <td>5</td>\n",
       "      <td>0.612</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>msmarco</td>\n",
       "      <td>10</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.664</td>\n",
       "      <td>0.803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>pubmedqa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>pubmedqa</td>\n",
       "      <td>3</td>\n",
       "      <td>0.387</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>pubmedqa</td>\n",
       "      <td>5</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>pubmedqa</td>\n",
       "      <td>10</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>tatqa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>tatqa</td>\n",
       "      <td>3</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>tatqa</td>\n",
       "      <td>5</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>tatqa</td>\n",
       "      <td>10</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>techqa</td>\n",
       "      <td>1</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0.287</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>techqa</td>\n",
       "      <td>3</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>techqa</td>\n",
       "      <td>5</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.472</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>intfloat/multilingual-e5-base</td>\n",
       "      <td>techqa</td>\n",
       "      <td>10</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model_name      subset   k  precision  recall     f1    mrr\n",
       "0   intfloat/multilingual-e5-base     covidqa   1      0.437   0.312  0.361  0.428\n",
       "1   intfloat/multilingual-e5-base     covidqa   3      0.394   0.427  0.407  0.481\n",
       "2   intfloat/multilingual-e5-base     covidqa   5      0.358   0.502  0.415  0.513\n",
       "3   intfloat/multilingual-e5-base     covidqa  10      0.301   0.621  0.402  0.542\n",
       "4   intfloat/multilingual-e5-base        cuad   1      0.518   0.394  0.445  0.551\n",
       "5   intfloat/multilingual-e5-base        cuad   3      0.467   0.512  0.486  0.589\n",
       "6   intfloat/multilingual-e5-base        cuad   5      0.423   0.587  0.489  0.613\n",
       "7   intfloat/multilingual-e5-base        cuad  10      0.367   0.703  0.481  0.641\n",
       "8   intfloat/multilingual-e5-base  delucionqa   1      0.638   0.591  0.612  0.703\n",
       "9   intfloat/multilingual-e5-base  delucionqa   3      0.594   0.672  0.629  0.731\n",
       "10  intfloat/multilingual-e5-base  delucionqa   5      0.552   0.728  0.627  0.752\n",
       "11  intfloat/multilingual-e5-base  delucionqa  10      0.483   0.815  0.606  0.779\n",
       "12  intfloat/multilingual-e5-base     emanual   1      0.419   0.273  0.329  0.402\n",
       "13  intfloat/multilingual-e5-base     emanual   3      0.381   0.394  0.386  0.443\n",
       "14  intfloat/multilingual-e5-base     emanual   5      0.343   0.458  0.390  0.469\n",
       "15  intfloat/multilingual-e5-base     emanual  10      0.287   0.572  0.381  0.501\n",
       "16  intfloat/multilingual-e5-base    expertqa   1      0.452   0.327  0.378  0.443\n",
       "17  intfloat/multilingual-e5-base    expertqa   3      0.401   0.432  0.412  0.482\n",
       "18  intfloat/multilingual-e5-base    expertqa   5      0.358   0.502  0.415  0.501\n",
       "19  intfloat/multilingual-e5-base    expertqa  10      0.301   0.621  0.402  0.527\n",
       "20  intfloat/multilingual-e5-base       finqa   1      0.567   0.452  0.502  0.592\n",
       "21  intfloat/multilingual-e5-base       finqa   3      0.512   0.583  0.543  0.628\n",
       "22  intfloat/multilingual-e5-base       finqa   5      0.473   0.652  0.547  0.653\n",
       "23  intfloat/multilingual-e5-base       finqa  10      0.412   0.758  0.533  0.681\n",
       "24  intfloat/multilingual-e5-base      hagrid   1      0.403   0.258  0.313  0.387\n",
       "25  intfloat/multilingual-e5-base      hagrid   3      0.372   0.382  0.376  0.428\n",
       "26  intfloat/multilingual-e5-base      hagrid   5      0.332   0.439  0.376  0.451\n",
       "27  intfloat/multilingual-e5-base      hagrid  10      0.274   0.553  0.366  0.483\n",
       "28  intfloat/multilingual-e5-base    hotpotqa   1      0.672   0.618  0.643  0.713\n",
       "29  intfloat/multilingual-e5-base    hotpotqa   3      0.627   0.703  0.662  0.742\n",
       "30  intfloat/multilingual-e5-base    hotpotqa   5      0.583   0.762  0.659  0.763\n",
       "31  intfloat/multilingual-e5-base    hotpotqa  10      0.512   0.847  0.637  0.791\n",
       "32  intfloat/multilingual-e5-base     msmarco   1      0.693   0.642  0.666  0.728\n",
       "33  intfloat/multilingual-e5-base     msmarco   3      0.652   0.723  0.685  0.759\n",
       "34  intfloat/multilingual-e5-base     msmarco   5      0.612   0.782  0.686  0.778\n",
       "35  intfloat/multilingual-e5-base     msmarco  10      0.543   0.862  0.664  0.803\n",
       "36  intfloat/multilingual-e5-base    pubmedqa   1      0.428   0.302  0.354  0.421\n",
       "37  intfloat/multilingual-e5-base    pubmedqa   3      0.387   0.413  0.398  0.467\n",
       "38  intfloat/multilingual-e5-base    pubmedqa   5      0.352   0.487  0.407  0.492\n",
       "39  intfloat/multilingual-e5-base    pubmedqa  10      0.294   0.603  0.395  0.518\n",
       "40  intfloat/multilingual-e5-base       tatqa   1      0.553   0.438  0.488  0.578\n",
       "41  intfloat/multilingual-e5-base       tatqa   3      0.502   0.567  0.531  0.612\n",
       "42  intfloat/multilingual-e5-base       tatqa   5      0.462   0.638  0.536  0.637\n",
       "43  intfloat/multilingual-e5-base       tatqa  10      0.403   0.743  0.522  0.663\n",
       "44  intfloat/multilingual-e5-base      techqa   1      0.431   0.287  0.343  0.413\n",
       "45  intfloat/multilingual-e5-base      techqa   3      0.393   0.403  0.397  0.452\n",
       "46  intfloat/multilingual-e5-base      techqa   5      0.354   0.472  0.403  0.478\n",
       "47  intfloat/multilingual-e5-base      techqa  10      0.302   0.588  0.398  0.507"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = pd.DataFrame()\n",
    "\n",
    "for subset in subsets:\n",
    "    metrics = pd.concat([metrics, calculate_metrics(subset, rerank_serp(subset))])\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77f0e1c-3439-4da8-b2df-1682e8ad3503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c7d4c5-2a6e-47b0-8691-b0ff5f94ff83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
